{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f77d402-73c8-4eb0-95b4-32cb654fe3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "from onnxruntime.quantization import QuantFormat, QuantType, quantize_static\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063d9443-9459-4cd7-ae9b-b6194bfc75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_images(images_folder: str):\n",
    "    providers = ['DmlExecutionProvider']\n",
    "    options = ort.SessionOptions()\n",
    "    options.enable_mem_pattern = False\n",
    "    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "    decomposer_sess = ort.InferenceSession('./preprocessed/decomposer.onnx', sess_options=options, providers=providers)\n",
    "    combiner_sess = ort.InferenceSession('./preprocessed/combiner.onnx', sess_options=options, providers=providers)\n",
    "    morpher_sess = ort.InferenceSession('./preprocessed/morpher.onnx', sess_options=options, providers=providers)\n",
    "    batch_filenames = os.listdir(images_folder)\n",
    "    batch_data = []\n",
    "    for image_name in tqdm(batch_filenames):\n",
    "        image_filepath = os.path.join(images_folder, image_name)\n",
    "        img = cv2.imread(image_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (450,900),interpolation = cv2.INTER_LANCZOS4)\n",
    "        padding_img = np.zeros((1024,1024,4),np.uint8)\n",
    "        padding_img[40:40+900,287:287+450,:] = img\n",
    "        img = cv2.resize(padding_img, (512,512),interpolation = cv2.INTER_LANCZOS4)\n",
    "\n",
    "        decomposer_res = decomposer_sess.run(None, {'input_image':img})\n",
    "        for i in range(1): #Repeat 2 times\n",
    "            eyebrow_pose = np.zeros((1,12), np.float32)\n",
    "            rand_idx = int(np.random.randint(low = 0, high = 5))\n",
    "            eyebrow_pose[0, 2 * rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            eyebrow_pose[0, 2 * rand_idx + 1] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            combiner_inp = {'image_prepared':decomposer_res[2], \n",
    "                            'eyebrow_background_layer':decomposer_res[0], \n",
    "                            'eyebrow_layer':decomposer_res[1], \n",
    "                            'eyebrow_pose':eyebrow_pose}\n",
    "            combiner_res = combiner_sess.run(None, combiner_inp)\n",
    "            for j in range(1):\n",
    "                face_pose = np.zeros((1,27),np.float32)\n",
    "                rand_idx = int(np.random.randint(low = 0, high = 5))\n",
    "                face_pose[0, 2 * rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 2 * rand_idx + 1] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                rand_idx = int(np.random.randint(low = 12, high = 22))\n",
    "                face_pose[0, rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 23] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 24] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 25] = np.random.default_rng().uniform(-1.0,1.0)\n",
    "                face_pose[0, 26] = np.random.default_rng().uniform(-1.0,1.0)\n",
    "                morpher_inp = {\n",
    "                    'image_prepared':decomposer_res[2],\n",
    "                    'im_morpher_crop':combiner_res[0],\n",
    "                    'face_pose':face_pose,\n",
    "                    '/face_morpher/downsample_blocks.3/downsample_blocks.3.2/Relu_output_0':combiner_res[1]\n",
    "                }\n",
    "                morpher_res = morpher_sess.run(None, morpher_inp)\n",
    "                for k in range(3):\n",
    "                    body_pose = np.random.uniform(-1.0,1.0,[1,6]).astype(np.float32)\n",
    "                    body_pose[0,5] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                    rotator_inp = {\n",
    "                        'face_morphed_half':morpher_res[1],\n",
    "                        'rotation_pose':body_pose\n",
    "                    }\n",
    "                    batch_data.append(rotator_inp)\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b89715e-23d4-4901-84ce-214144bf9bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298/298 [00:29<00:00, 10.12it/s]\n"
     ]
    }
   ],
   "source": [
    "class RotatorDataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder: str):\n",
    "        self.enum_data = None\n",
    "\n",
    "        # Convert image to input data\n",
    "        self.data_list = _preprocess_images(\n",
    "            calibration_image_folder\n",
    "        )\n",
    "        self.datasize = len(self.data_list)\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.enum_data is None:\n",
    "            self.enum_data = iter(self.data_list)\n",
    "        return next(self.enum_data, None)\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = None\n",
    "dr = RotatorDataReader('Z:/ComfyUI-aki-v1.5/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe66d039-f88d-4f3c-b676-43dbea81c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.downsample_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.downsample_blocks.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.downsample_blocks.2.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.downsample_blocks.3.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.0.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.0.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.1.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.1.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.2.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.2.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.3.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.3.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.4.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.4.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.5.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.bottleneck_blocks.5.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.upsample_blocks.0.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.upsample_blocks.1.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'two_algo_face_body_rotator.encoder_decoder.upsample_blocks.2.1.1.weight' with rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Concat', 'Relu', 'Transpose', 'GlobalAveragePool', 'Unsqueeze', 'Pad', 'Clip', 'ConvTranspose', 'Softmax', 'LayerNormalization', 'Gemm', 'Conv', 'MatMul', 'LeakyRelu', 'Reshape', 'ArgMax', 'AveragePool', 'InstanceNormalization', 'Squeeze', 'MaxPool', 'EmbedLayerNormalization', 'Slice', 'Add', 'Sigmoid', 'Resize', 'Split', 'Mul', 'Where', 'Gather', 'GatherElements', 'BatchNormalization']\n",
      " 16\n",
      "com.microsoft.nchwc 1\n",
      "ai.onnx.ml 5\n",
      "ai.onnx.training 1\n",
      "ai.onnx.preview.training 1\n",
      "com.microsoft 1\n",
      "com.microsoft.experimental 1\n",
      "org.pytorch.aten 1\n",
      "com.microsoft.dml 1\n",
      "[domain: \"\"\n",
      "version: 16\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "quantize_static(\n",
    "        './preprocessed/rotator.onnx',\n",
    "        './quantized/rotator.onnx',\n",
    "        dr,\n",
    "        quant_format=QuantFormat.QDQ,\n",
    "        per_channel=True,\n",
    "        weight_type=QuantType.QInt8,\n",
    "        # nodes_to_exclude = ['/eyebrow_morphing_combiner/Sub', '/eyebrow_morphing_combiner/Add_2', '/eyebrow_morphing_combiner/Sub_1'],\n",
    "        extra_options = {\n",
    "            'ActivationSymmetric':True,\n",
    "            'QuantizeBias':False\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57d34fd-343d-429e-83d0-ea1eecb32694",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_quantized_session =ort.InferenceSession('./preprocessed/rotator.onnx', None)\n",
    "quantized_session =ort.InferenceSession('./quantized/rotator.onnx', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95efa410-35d2-4793-afcb-725e55f56939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.04607301)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dr.rewind()\n",
    "inp = dr.get_next()\n",
    "non_res =  non_quantized_session.run(None, inp)\n",
    "qt_res = quantized_session.run(None, inp)\n",
    "((qt_res[0] -non_res[0])**2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
