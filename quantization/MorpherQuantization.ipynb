{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965a50d3-1fed-4913-92c5-7eb3867d9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "from onnxruntime.quantization import QuantFormat, QuantType, quantize_static\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba82a68-67a2-4592-a12d-3c28a9599072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_images(images_folder: str):\n",
    "    providers = ['DmlExecutionProvider']\n",
    "    options = ort.SessionOptions()\n",
    "    options.enable_mem_pattern = False\n",
    "    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "    decomposer_sess = ort.InferenceSession('./preprocessed/decomposer.onnx', sess_options=options, providers=providers)\n",
    "    combiner_sess = ort.InferenceSession('./preprocessed/combiner.onnx', sess_options=options, providers=providers)\n",
    "    batch_filenames = os.listdir(images_folder)\n",
    "    batch_data = []\n",
    "    for image_name in tqdm(batch_filenames):\n",
    "        image_filepath = os.path.join(images_folder, image_name)\n",
    "        img = cv2.imread(image_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (450,900),interpolation = cv2.INTER_LANCZOS4)\n",
    "        padding_img = np.zeros((1024,1024,4),np.uint8)\n",
    "        padding_img[40:40+900,287:287+450,:] = img\n",
    "        img = cv2.resize(padding_img, (512,512),interpolation = cv2.INTER_LANCZOS4)\n",
    "\n",
    "        decomposer_res = decomposer_sess.run(None, {'input_image':img})\n",
    "        for i in range(2): #Repeat 2 times\n",
    "            eyebrow_pose = np.zeros((1,12), np.float32)\n",
    "            rand_idx = int(np.random.randint(low = 0, high = 5))\n",
    "            eyebrow_pose[0, 2 * rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            eyebrow_pose[0, 2 * rand_idx + 1] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            combiner_inp = {'image_prepared':decomposer_res[2], \n",
    "                            'eyebrow_background_layer':decomposer_res[0], \n",
    "                            'eyebrow_layer':decomposer_res[1], \n",
    "                            'eyebrow_pose':eyebrow_pose}\n",
    "            combiner_res = combiner_sess.run(None, combiner_inp)\n",
    "            for j in range(3):\n",
    "                face_pose = np.zeros((1,27),np.float32)\n",
    "                rand_idx = int(np.random.randint(low = 0, high = 5))\n",
    "                face_pose[0, 2 * rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 2 * rand_idx + 1] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                rand_idx = int(np.random.randint(low = 12, high = 22))\n",
    "                face_pose[0, rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 23] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 24] = np.random.default_rng().uniform(0.0,1.0)\n",
    "                face_pose[0, 25] = np.random.default_rng().uniform(-1.0,1.0)\n",
    "                face_pose[0, 26] = np.random.default_rng().uniform(-1.0,1.0)\n",
    "                data_inp = {\n",
    "                    'image_prepared':decomposer_res[2],\n",
    "                    'im_morpher_crop':combiner_res[0],\n",
    "                    'face_pose':face_pose,\n",
    "                    '/face_morpher/downsample_blocks.3/downsample_blocks.3.2/Relu_output_0':combiner_res[1]\n",
    "                }\n",
    "                batch_data.append(data_inp)\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bb5148-b27c-4540-8800-36b5fddbd9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298/298 [00:29<00:00, 10.24it/s]\n"
     ]
    }
   ],
   "source": [
    "class MorpherDataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder: str):\n",
    "        self.enum_data = None\n",
    "\n",
    "        # Convert image to input data\n",
    "        self.data_list = _preprocess_images(\n",
    "            calibration_image_folder\n",
    "        )\n",
    "        self.datasize = len(self.data_list)\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.enum_data is None:\n",
    "            self.enum_data = iter(self.data_list)\n",
    "        return next(self.enum_data, None)\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = None\n",
    "dr = MorpherDataReader('Z:/ComfyUI-aki-v1.5/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5762708-210c-47e4-b713-3985b68d38c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.1.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.1.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.2.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.2.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.3.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.3.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.4.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.4.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.5.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.bottleneck_blocks.5.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.upsample_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.upsample_blocks.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.upsample_blocks.2.1.weight' with rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BatchNormalization', 'Pad', 'MatMul', 'Split', 'Softmax', 'Sigmoid', 'EmbedLayerNormalization', 'ArgMax', 'GlobalAveragePool', 'Transpose', 'Relu', 'Clip', 'Slice', 'Add', 'Mul', 'Squeeze', 'InstanceNormalization', 'Unsqueeze', 'Gemm', 'ConvTranspose', 'Concat', 'LeakyRelu', 'Resize', 'MaxPool', 'Reshape', 'Where', 'Gather', 'GatherElements', 'LayerNormalization', 'Conv', 'AveragePool']\n",
      " 16\n",
      "com.microsoft.nchwc 1\n",
      "ai.onnx.ml 5\n",
      "ai.onnx.training 1\n",
      "ai.onnx.preview.training 1\n",
      "com.microsoft 1\n",
      "com.microsoft.experimental 1\n",
      "org.pytorch.aten 1\n",
      "com.microsoft.dml 1\n",
      "[domain: \"\"\n",
      "version: 16\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "quantize_static(\n",
    "        './preprocessed/morpher.onnx',\n",
    "        './quantized/morpher.onnx',\n",
    "        dr,\n",
    "        quant_format=QuantFormat.QDQ,\n",
    "        per_channel=True,\n",
    "        weight_type=QuantType.QInt8,\n",
    "        # nodes_to_exclude = ['/eyebrow_morphing_combiner/Sub', '/eyebrow_morphing_combiner/Add_2', '/eyebrow_morphing_combiner/Sub_1'],\n",
    "        extra_options = {\n",
    "            'ActivationSymmetric':True,\n",
    "            'QuantizeBias':False\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b27c613-e45b-47f0-9b93-9933dc2bd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_quantized_session =ort.InferenceSession('./preprocessed/morpher.onnx', None)\n",
    "quantized_session =ort.InferenceSession('./quantized/morpher.onnx', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bad6c1e-f5d8-47ff-9651-379f7b5660e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.019908015)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dr.rewind()\n",
    "inp = dr.get_next()\n",
    "non_res =  non_quantized_session.run(None, inp)\n",
    "qt_res = quantized_session.run(None, inp)\n",
    "((qt_res[1] -non_res[1])**2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
