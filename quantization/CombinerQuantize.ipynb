{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64b82e7-ba42-4c37-9599-cfe8290fae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "from onnxruntime.quantization import QuantFormat, QuantType, quantize_static\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b91c4c8-cf60-4f31-9be1-5299cd0daafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_images(images_folder: str):\n",
    "    providers = ['DmlExecutionProvider']\n",
    "    options = ort.SessionOptions()\n",
    "    options.enable_mem_pattern = False\n",
    "    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "    decomposer_sess = ort.InferenceSession('./preprocessed/decomposer.onnx', sess_options=options, providers=providers)\n",
    "    batch_filenames = os.listdir(images_folder)\n",
    "    batch_data = []\n",
    "    for image_name in tqdm(batch_filenames):\n",
    "        image_filepath = os.path.join(images_folder, image_name)\n",
    "        img = cv2.imread(image_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (450,900),interpolation = cv2.INTER_LANCZOS4)\n",
    "        padding_img = np.zeros((1024,1024,4),np.uint8)\n",
    "        padding_img[40:40+900,287:287+450,:] = img\n",
    "        img = cv2.resize(padding_img, (512,512),interpolation = cv2.INTER_LANCZOS4)\n",
    "\n",
    "        decomposer_res = decomposer_sess.run(None, {'input_image':img})\n",
    "        for i in range(3): #Repeat 3 times\n",
    "            eyebrow_pose = np.zeros((1,12), np.float32)\n",
    "            rand_idx = int(np.random.randint(low = 0, high = 5))\n",
    "            eyebrow_pose[0, 2 * rand_idx] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            eyebrow_pose[0, 2 * rand_idx + 1] = np.random.default_rng().uniform(0.0,1.0)\n",
    "            batch_data.append({'image_prepared':decomposer_res[2], 'eyebrow_background_layer':decomposer_res[0], 'eyebrow_layer':decomposer_res[1], 'eyebrow_pose':eyebrow_pose})\n",
    "        \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f6bb75-39c8-4500-8120-d03da342336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinerDataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder: str):\n",
    "        self.enum_data = None\n",
    "\n",
    "        # Convert image to input data\n",
    "        self.data_list = _preprocess_images(\n",
    "            calibration_image_folder\n",
    "        )\n",
    "        self.datasize = len(self.data_list)\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.enum_data is None:\n",
    "            self.enum_data = iter(self.data_list)\n",
    "        return next(self.enum_data, None)\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e568e56b-9895-4c61-b6d4-69d962eb3f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298/298 [00:23<00:00, 12.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dr = CombinerDataReader('Z:/ComfyUI-aki-v1.5/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3badcdd0-6c76-48fa-aabf-ebb099fcf333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.downsample_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.downsample_blocks.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.downsample_blocks.2.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.downsample_blocks.3.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.1.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.1.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.2.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.2.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.3.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.3.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.4.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.4.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.5.resnet_path.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.bottleneck_blocks.5.resnet_path.4.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.upsample_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.upsample_blocks.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'eyebrow_morphing_combiner.body.upsample_blocks.2.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.downsample_blocks.0.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.downsample_blocks.1.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.downsample_blocks.2.1.weight' with rank 1\n",
      "WARNING:root:Axis 1 is out-of-range for weight 'face_morpher.downsample_blocks.3.1.weight' with rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reshape', 'Transpose', 'Concat', 'Resize', 'Gather', 'Slice', 'AveragePool', 'Unsqueeze', 'GlobalAveragePool', 'BatchNormalization', 'Add', 'Pad', 'Conv', 'ArgMax', 'LeakyRelu', 'Gemm', 'InstanceNormalization', 'Softmax', 'Clip', 'GatherElements', 'Split', 'MaxPool', 'Relu', 'MatMul', 'EmbedLayerNormalization', 'LayerNormalization', 'Sigmoid', 'ConvTranspose', 'Squeeze', 'Where', 'Mul']\n",
      " 16\n",
      " 16\n",
      "com.microsoft.nchwc 1\n",
      "ai.onnx.ml 5\n",
      "ai.onnx.training 1\n",
      "ai.onnx.preview.training 1\n",
      "com.microsoft 1\n",
      "com.microsoft.experimental 1\n",
      "org.pytorch.aten 1\n",
      "com.microsoft.dml 1\n",
      "[domain: \"\"\n",
      "version: 16\n",
      ", domain: \"\"\n",
      "version: 16\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "quantize_static(\n",
    "        './preprocessed/combiner.onnx',\n",
    "        './quantized/combiner.onnx',\n",
    "        dr,\n",
    "        quant_format=QuantFormat.QDQ,\n",
    "        per_channel=True,\n",
    "        weight_type=QuantType.QInt8,\n",
    "        nodes_to_exclude = ['/eyebrow_morphing_combiner/Sub', '/eyebrow_morphing_combiner/Add_2', '/eyebrow_morphing_combiner/Sub_1'],\n",
    "        extra_options = {\n",
    "            'ActivationSymmetric':True,\n",
    "            'QuantizeBias':False\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16a69de-542d-4f3f-9798-cb17ce78f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_quantized_session =ort.InferenceSession('./preprocessed/combiner.onnx', None)\n",
    "quantized_session =ort.InferenceSession('./quantized/combiner.onnx', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48f58a4-fa2e-4c24-b7bb-b3e12f2b8d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.00036856649)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.rewind()\n",
    "inp = dr.get_next()\n",
    "non_res =  non_quantized_session.run(None, inp)\n",
    "qt_res = quantized_session.run(None, inp)\n",
    "((qt_res[0] -non_res[0])**2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
